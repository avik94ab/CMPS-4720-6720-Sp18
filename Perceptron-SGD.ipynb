{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to 2.7.14 |Anaconda custom (64-bit)| (default, Oct  5 2017, 02:28:52) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "\n",
      "\n",
      "===Importing the necessary libraries for the project===\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created by Avik Bhattacharya\n",
    "CMPS 4720/6720 Homework: Implement your own classification algorithm\n",
    "'''\n",
    "\n",
    "import sys\n",
    "print \"Welcome to %s\\n\\n\"%sys.version\n",
    "print '===Importing the necessary libraries for the project==='\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sign function is used to activate the neuron\n",
    "'''\n",
    "def activation(x):\n",
    "    if x>1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Stochastic gradient descent used for learning weights\n",
    "'''\n",
    "def train_algorithm(data,n_iter,learn_rate):\n",
    "    weights=[]\n",
    "    '''\n",
    "    The weight vector is initialised with all zeros\n",
    "    '''\n",
    "    for i in range(1,np.shape(data)[1]):\n",
    "        weights.append(0)\n",
    "    '''\n",
    "    n_iter is the terminating condition\n",
    "    '''\n",
    "    for i in range (0,n_iter):\n",
    "        for k in range(0,len(data)):\n",
    "            inputs=data[k][0:np.shape(data)[1]-1]\n",
    "            label=data[k][np.shape(data)[1]-1:np.shape(data)[1]]\n",
    "            adder=0\n",
    "            for i in range (1,np.shape(data)[1]):\n",
    "                adder += inputs[i-1]*weights[i-1]\n",
    "            '''\n",
    "            Perceptron delta learning rule implemented\n",
    "            '''\n",
    "            guess=activation((adder))\n",
    "            \n",
    "            error=(label-guess)\n",
    "            #print \"Guess=%d ,Target=%d, Error=%d\"%(guess,label ,error)\n",
    "            weights=weights+learn_rate*(error*inputs)\n",
    "    return weights   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Learned weights used for sample classification using trained model\n",
    "'''\n",
    "def test_algorithm(data,w):\n",
    "    predicted=[]\n",
    "    weights=w\n",
    "    for k in range(0,len(data)):\n",
    "        inputs=data[k][0:np.shape(data)[1]-1]\n",
    "        adder=0\n",
    "        for i in range(1,np.shape(data)[1]):\n",
    "            adder += inputs[i-1]*weights[i-1]\n",
    "        guess=activation(adder)\n",
    "        predicted.append(guess)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Accuracy, TP, TN, FP, FN are evaluated\n",
    "'''\n",
    "def metrics(predicted, labels):\n",
    "    tp=0.0\n",
    "    fp=0.0\n",
    "    tn=0.0\n",
    "    fn=0.0\n",
    "    for i in range(0,len(labels)):\n",
    "        if (labels[i]==1):\n",
    "            if (predicted[i]==1):\n",
    "                tp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        if (labels[i]==0):\n",
    "            if (predicted[i]==0):\n",
    "                tn+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "    \n",
    "    accuracy=(tp+tn)*1.0/(tp+tn+fp+fn)\n",
    "    return accuracy,tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to return a feature set and labels ready to train classifier \n",
    "'''\n",
    "def read_source(filename):\n",
    "    df1=pd.read_csv(filename, header=None)\n",
    "    data=df1.values\n",
    "    '''\n",
    "    for loop used swap first and last column because initially\n",
    "    the model was developed considering the last column to be label,\n",
    "    so modified it to keep up with the pattern earlier developed\n",
    "    '''\n",
    "    for i in range (0,len(data)):\n",
    "        temp=data[i][0]\n",
    "        data[i][0]=data[i][np.shape(data)[1]-1]\n",
    "        data[i][np.shape(data)[1]-1]=temp\n",
    "    s=(np.shape(data)[0],np.shape(data)[1]+1)\n",
    "    a=np.ones(s)\n",
    "    '''\n",
    "    label 1 is kept as 1\n",
    "    label 0 converted to -1\n",
    "    '''\n",
    "    '''\n",
    "    for i in range(0,len(data)):\n",
    "        if (data[i][np.shape(data)[1]-1]==0):\n",
    "            data[i][np.shape(data)[1]-1]=0\n",
    "    '''\n",
    "    '''\n",
    "    padding extra 1s at x0 positions\n",
    "    '''\n",
    "    for i in range (0,np.shape(data)[1]):\n",
    "        for j in range(0,len(data)):\n",
    "            a[j][i+1]=data[j][i]\n",
    "    data=a\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef validate_set(arr,percentage):\\n    np.random.shuffle(arr)\\n    if((percentage*1.0/100)*(len(arr))==0):\\n        r=1\\n    else:\\n        r=int(((percentage*1.0/100)*(len(arr))))\\n    m = len(arr)-r\\n    k = np.shape(arr)[1]\\n    s=(m,k)\\n    test=np.zeros(s)\\n    size=(r,np.shape(arr)[1])\\n    val=np.zeros(size)\\n    for i in range(0,r):\\n        val[i][0:np.shape(arr)[1]]=arr[i][0:np.shape(arr)[1]]\\n    for i in range(r,(len(arr))):\\n        test[i-r][0:np.shape(arr)[1]]=arr[i][0:np.shape(arr)[1]]\\n    \\n    return test,val\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def validate_set(arr,percentage):\n",
    "    np.random.shuffle(arr)\n",
    "    if((percentage*1.0/100)*(len(arr))==0):\n",
    "        r=1\n",
    "    else:\n",
    "        r=int(((percentage*1.0/100)*(len(arr))))\n",
    "    m = len(arr)-r\n",
    "    k = np.shape(arr)[1]\n",
    "    s=(m,k)\n",
    "    test=np.zeros(s)\n",
    "    size=(r,np.shape(arr)[1])\n",
    "    val=np.zeros(size)\n",
    "    for i in range(0,r):\n",
    "        val[i][0:np.shape(arr)[1]]=arr[i][0:np.shape(arr)[1]]\n",
    "    for i in range(r,(len(arr))):\n",
    "        test[i-r][0:np.shape(arr)[1]]=arr[i][0:np.shape(arr)[1]]\n",
    "    \n",
    "    return test,val\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef plotter(start,end,step):\\n    final=[]\\n    \\n    y_axis_err=[]\\n    percentage=20\\n    print '\\n Randomly select %d percent of training set for tuning the number of iterations required\\n'%(percentage)\\n    print 'Validating on 10 randomly selected models'\\n    #train_data=read_source('train.txt')\\n    #train_data,val_data=validate_set(train_data,percentage)\\n    learn_rate=0.001\\n    for k in range(0,10):\\n        y_axis=[]\\n        train_data=read_source('train.txt')\\n        train_data,val_data=validate_set(train_data,percentage)\\n        for n_iter in range(start,end,step):\\n            w=train_algorithm(train_data,n_iter,learn_rate)\\n            test_data=val_data\\n            predicted=test_algorithm(test_data,w)\\n            labels=[]\\n            for i in range(0,len(test_data)):\\n                labels.append(test_data[i][np.shape(test_data)[1]-1])\\n                labels[i]=int(labels[i])\\n            accuracy,tp,tn,fp,fn= metrics(predicted,labels)\\n            err=(1-accuracy)\\n            y_axis.append(accuracy)\\n            y_axis_err.append(err)\\n        xaxis = np.arange(start,end,step)\\n        fig, ax = plt.subplots()\\n        ax.plot(xaxis, y_axis, 'b')\\n        ax.set_xlabel('No. of iterations (n_iter)')\\n        ax.set_ylabel('Classification Accuracy')\\n        plt.title('Accuracy w.r.t n_iter')\\n        plt.savefig('n_iter vs acc.pdf')\\n        plt.show()\\n        ymax=max(y_axis)\\n        for i in range(start,end,step):\\n            if(y_axis[i]==ymax and  y_axis[i-1]!=y_axis[i]):\\n                n=i\\n        print 'Best accuracy of %d th model is at n_ter=%d'%(k+1,n)\\n        final.append(n)\\n    return final\\n \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Plotter function\n",
    "'''\n",
    "'''\n",
    "def plotter(start,end,step):\n",
    "    final=[]\n",
    "    \n",
    "    y_axis_err=[]\n",
    "    percentage=20\n",
    "    print '\\n Randomly select %d percent of training set for tuning the number of iterations required\\n'%(percentage)\n",
    "    print 'Validating on 10 randomly selected models'\n",
    "    #train_data=read_source('train.txt')\n",
    "    #train_data,val_data=validate_set(train_data,percentage)\n",
    "    learn_rate=0.001\n",
    "    for k in range(0,10):\n",
    "        y_axis=[]\n",
    "        train_data=read_source('train.txt')\n",
    "        train_data,val_data=validate_set(train_data,percentage)\n",
    "        for n_iter in range(start,end,step):\n",
    "            w=train_algorithm(train_data,n_iter,learn_rate)\n",
    "            test_data=val_data\n",
    "            predicted=test_algorithm(test_data,w)\n",
    "            labels=[]\n",
    "            for i in range(0,len(test_data)):\n",
    "                labels.append(test_data[i][np.shape(test_data)[1]-1])\n",
    "                labels[i]=int(labels[i])\n",
    "            accuracy,tp,tn,fp,fn= metrics(predicted,labels)\n",
    "            err=(1-accuracy)\n",
    "            y_axis.append(accuracy)\n",
    "            y_axis_err.append(err)\n",
    "        xaxis = np.arange(start,end,step)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(xaxis, y_axis, 'b')\n",
    "        ax.set_xlabel('No. of iterations (n_iter)')\n",
    "        ax.set_ylabel('Classification Accuracy')\n",
    "        plt.title('Accuracy w.r.t n_iter')\n",
    "        plt.savefig('n_iter vs acc.pdf')\n",
    "        plt.show()\n",
    "        ymax=max(y_axis)\n",
    "        for i in range(start,end,step):\n",
    "            if(y_axis[i]==ymax and  y_axis[i-1]!=y_axis[i]):\n",
    "                n=i\n",
    "        print 'Best accuracy of %d th model is at n_ter=%d'%(k+1,n)\n",
    "        final.append(n)\n",
    "    return final\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===We train and test our method by varying the number of iterations===\n",
      "===See the plot===\n",
      "The weight vector is:\n",
      "\n",
      "[ 0.806  0.095  0.024 -0.012 -0.097  0.07   0.004  0.064  0.092  0.144\n",
      " -0.02   0.004  0.124  0.012  0.121 -0.035 -0.016  0.089  0.084  0.036\n",
      "  0.054  0.06  -0.021]\n",
      "\n",
      "\n",
      "The model built on the basis of 100 iterations performs as below\n",
      "\n",
      "\n",
      "Accuracy=76.470588% \n",
      "tp=130 \n",
      "tn=13 \n",
      "fp=2 \n",
      "fn=42\n",
      "\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"===We train and test our method by varying the number of iterations===\\n===See the plot===\"\n",
    "\n",
    "'''\n",
    "Start, stop and step values for the plotter function\n",
    "'''\n",
    "\n",
    "start=0\n",
    "end=100\n",
    "step=1\n",
    "train_data=read_source('train.txt')\n",
    "test_data=read_source('test.txt')\n",
    "n_iter=100\n",
    "learn_rate=0.001 # for AND function change this to 1 to make it converge quicker\n",
    "w=train_algorithm(train_data,n_iter,learn_rate)\n",
    "print \"The weight vector is:\\n\"\n",
    "print w\n",
    "print \"\\n\"\n",
    "predicted=test_algorithm(test_data,w)\n",
    "labels=[]\n",
    "for i in range(0,len(test_data)):\n",
    "    labels.append(test_data[i][np.shape(test_data)[1]-1])\n",
    "    labels[i]=int(labels[i])\n",
    "accuracy,tp,tn,fp,fn= metrics(predicted,labels)\n",
    "print \"The model built on the basis of %d iterations performs as below\\n\"%(n_iter)\n",
    "print \"\\nAccuracy=%f%% \\ntp=%d \\ntn=%d \\nfp=%d \\nfn=%d\\n\"%(accuracy*100,tp,tn,fp,fn)\n",
    "print \"Done\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
